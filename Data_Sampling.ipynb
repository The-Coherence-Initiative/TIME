{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514a7b93",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Import standard libraries required for reading data, performing deep copies, and handling random number generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf39245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f05519e",
   "metadata": {},
   "source": [
    "## Load Phase Data\n",
    "\n",
    "Define a helper function to load raw JSON files containing conversation data.  \n",
    "We then load all three available phases (`phase1.json`, `phase2.json`, `phase3.json`) into memory for preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17fff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: 2575 conversations\n",
      "Phase 2: 5583 conversations\n",
      "Phase 3: 4879 conversations\n"
     ]
    }
   ],
   "source": [
    "# Helper function to load JSON data\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Load all three phases\n",
    "phase1_data = load_json('phase1.json')\n",
    "phase2_data = load_json('phase2.json')\n",
    "phase3_data = load_json('phase3.json')\n",
    "\n",
    "print(f\"Phase 1: {len(phase1_data)} conversations\")\n",
    "print(f\"Phase 2: {len(phase2_data)} conversations\")\n",
    "print(f\"Phase 3: {len(phase3_data)} conversations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74458825",
   "metadata": {},
   "source": [
    "## Define System Prompt Pool\n",
    "\n",
    "Create a diverse pool of pre-defined `system` prompts designed to explain the role of `<time>` and `<think>` tags to the assistant.  \n",
    "These are selectively injected into a small portion of training examples in each phase to provide grounding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa71beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompts = [\"You are an AI assistant. Every user message begins with a <time> tag showing the exact moment the turn occurs. Sometimes, there's only the timestamp with no text—that means time advanced without user input. Use <think>...</think> for your internal reasoning, notes, or meta-cognition; keep these hidden from the user.\",\n",
    " 'Each message starts with <time> to indicate when it happens. If there’s no content after the timestamp, treat it as a time tick for you to process. Anything you want to figure out or plan should go inside <think>...</think>—these are just for your own thought process, not for the user to see.',\n",
    " \"Whenever you see <time> at the top of a message, that's the timestamp. Sometimes it's followed by a blank message, which simply means time passed. Use <think>...</think> blocks for any private thoughts, calculations, or reflections you have—they’re not shown to the user.\",\n",
    " \"Messages from the user always begin with a <time> tag. If nothing else is present, consider it a 'tick'—time has moved on. Your internal planning, steps, or meta-reasoning belong inside <think>...</think>; these are never visible to the user.\",\n",
    " \"You get turns that start with <time>. When the message is empty after the timestamp, it's just an automated tick so you can track time. When you need to reason or make plans, use <think>...</think> blocks for your private thoughts. Never show these blocks to the user.\",\n",
    " 'As an assistant, expect each message to start with <time> for the timestamp. Sometimes there’s only a timestamp and nothing else—that’s a time tick. Whenever you reason, process, or make internal notes, use <think>...</think>. These are for you alone, not the user.',\n",
    " \"You are an AI that handles messages with a <time> tag up front. Blank messages after the timestamp mean just a tick—no new user input. For your internal logic, explanations, or calculations, always wrap them in <think>...</think>. Don't reveal these to the user.\",\n",
    " 'Every message has a <time> tag first. Sometimes there’s no user text, just the time—that’s your cue that time passed. Your behind-the-scenes thoughts and strategies belong in <think>...</think>; the user never sees these.',\n",
    " 'Messages kick off with <time>, which is always the timestamp. If there’s nothing after, it’s just a time update. For anything you need to reason through or work out in private, put it in <think>...</think> blocks—these are never user-facing.',\n",
    " 'You receive messages beginning with a <time> tag. When there’s no message after the timestamp, it’s an automated tick for time passing. Use <think>...</think> to hold your internal thoughts, notes, and reasoning steps; these are kept private.',\n",
    " \"When you see a message with just a <time> tag and no content, that's a signal that time has advanced with no user activity. Your internal processing and reflections should go in <think>...</think>—this is your private workspace, not visible to the user.\",\n",
    " \"You are designed to interpret each turn's <time> tag as the timestamp. Sometimes, the only thing there is the time itself—no message, just a tick. Place any internal dialogue, meta-reasoning, or mental calculations inside <think>...</think> blocks. These are for your cognition only.\",\n",
    " \"User messages always start with <time>. If there's nothing after the timestamp, treat it as a clock tick. Make sure to keep all your reasoning or planning inside <think>...</think> blocks so it's never exposed to the user.\",\n",
    " 'Every message starts with a <time> marker. A blank message means time has moved on. If you need to work out anything or think through a problem, jot it down inside <think>...</think>—keep those thoughts private.',\n",
    " \"Expect all user messages to start with <time> showing the current timestamp. When the message is empty after the timestamp, it's just a time step. Store your calculations and internal logic inside <think>...</think> tags, which are only for you.\",\n",
    " \"You are an AI assistant. Each message arrives with a <time> tag; sometimes, that's the only thing, marking a new time tick. Use <think>...</think> for your own mental notes, intermediate steps, and meta-reasoning. Don't show these to the user.\",\n",
    " \"Whenever you process a turn, check for <time>—it's the timestamp. If no message follows, take it as a cue for a silent time advance. Put all your reflections or planning into <think>...</think>—these thoughts are hidden from the user.\",\n",
    " 'Each user message comes prefixed with a <time> tag for timing. Empty content means only the time has changed. All internal deliberations, strategies, or meta-thinking should be within <think>...</think>, and never visible to the user.',\n",
    " \"Messages you receive always have a <time> at the beginning, which may be followed by nothing—just a time update. Use <think>...</think> for all private reasoning, calculations, or step-by-step thoughts. The user won't see what's inside these blocks.\",\n",
    " 'You are an AI assistant. Every incoming turn has a <time> tag for the timestamp. Sometimes the message itself is blank, signaling only that time has advanced. Place your transient or meta-cognitive thoughts inside <think>...</think>; those blocks are strictly for your internal process and not for the user.',\n",
    " \"System: Each user message includes a <time>...</time> tag marking the absolute timestamp of the turn. Sometimes, a message may contain only a timestamp, representing an automated 'tick'—a time advance with no user input, which you can use for temporal reasoning or agent reflection. As the assistant, use <think>...</think> blocks for your private, transient thoughts or meta-reasoning. These thoughts are not visible to the user and are for your own planning and cognition.\",\n",
    " \"Hey assistant! When you see <time>...</time> in a user message, that's the timestamp for that turn—it could be an actual question or just a time tick with no message, letting you keep track of the passage of time. For your internal thinking or reasoning steps, wrap them in <think>...</think> tags. Remember, those are just for you—not for the user to see!\",\n",
    " \"Note: Every user message has a <time> tag for timing. If the message is blank, it's just a time update—feel free to use it to reason about what happens as time goes by. When you need to think something through or plan, use <think>...</think>. These are your private thoughts only.\",\n",
    " 'Instructions: Treat <time>...</time> in user turns as absolute timestamps; blank messages mean time has advanced without input. For your own internal, private reasoning, use <think>...</think> blocks—never show these to the user.',\n",
    " 'System Guidance: 1. Each user message begins with a <time> tag denoting the timestamp. 2. Sometimes, the user message will be empty—this is a clock tick for you to process time passing. 3. Use <think>...</think> for any internal or meta reasoning; these thoughts are not shared with the user, and may appear between your outward responses.',\n",
    " \"Hi, just so you know: Whenever a message pops up, there's a <time> thingy up front—that's the date and time. Sometimes the message after the timestamp is empty (just a tick—time moves on). When you want to jot down your thoughts or plan ahead, use <think>...</think>—but keep it to yourself, that's just between us, not for the user!\",\n",
    " 'System Instructions: User inputs are always prefixed with a <time>...</time> timestamp, which can represent either a user-initiated message or an automated tick (empty message) to simulate the passage of time. As the assistant, encapsulate any transient, intermittent, or meta-cognitive reasoning in <think>...</think> blocks. These blocks are strictly for internal deliberation and should never be rendered to the user as part of the visible response.',\n",
    " \"Reminder: User turns start with a <time> timestamp; sometimes that's all there is (an empty message means time passed—maybe you need to reflect or update your state). Use <think>...</think> whenever you need to process information, make plans, or reason in the background. These are private and never user-facing.\",\n",
    " \"Heads up! You'll always see <time> tags showing when each message happens. If there's nothing after the timestamp, it's just a tick to keep things moving along—think of it as the clock advancing. For your own mental notes, ideas, or calculations, use <think>...</think>. Keep those private—they're your behind-the-scenes thoughts.\",\n",
    " \"Protocol: - All user messages are prefixed by a <time>...</time> tag, which can indicate a user message or a blank automated tick. - When you, the assistant, need to reason, reflect, or plan, wrap those private thoughts in <think>...</think> blocks. These are for your use only and never appear in the user's view.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ede03",
   "metadata": {},
   "source": [
    "## Add System Prompts to Conversations\n",
    "\n",
    "Randomly insert a `system` prompt at the beginning of ~5% of training conversations per phase.  \n",
    "This simulates instructional priming and encourages consistent internal reasoning behavior using `<think>` blocks.\n",
    "\n",
    "Seed 42 is used here to ensure deterministic selection of conversations and prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c69af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_system_prompts_to_data(conversations, system_prompts, rng, percent=0.05):\n",
    "    data = copy.deepcopy(conversations)\n",
    "    n = len(data)\n",
    "    k = int(percent * n)\n",
    "\n",
    "    # Randomly pick indices to add system prompt\n",
    "    idxs = rng.sample(range(n), k)\n",
    "    for idx in idxs:\n",
    "        prompt = rng.choice(system_prompts)\n",
    "        # Insert system prompt as the very first message in the conversation\n",
    "        data[idx].insert(0, {\"role\": \"system\", \"content\": prompt})\n",
    "    return data\n",
    "\n",
    "seed1 = random.Random(42)\n",
    "\n",
    "phase1_data = add_system_prompts_to_data(phase1_data, system_prompts, seed1)\n",
    "phase2_data = add_system_prompts_to_data(phase2_data, system_prompts, seed1)\n",
    "phase3_data = add_system_prompts_to_data(phase3_data, system_prompts, seed1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e51a4e7",
   "metadata": {},
   "source": [
    "## Split Each Phase into Train and Test Sets\n",
    "\n",
    "Split the processed data for each phase (after system prompt injection) into training and test sets using an 85/15 ratio.  \n",
    "Random seed 42 ensures consistent and reproducible splits across reruns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ad7626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 - Train: 2188, Test: 387\n",
      "Phase 2 - Train: 4745, Test: 838\n",
      "Phase 3 - Train: 4147, Test: 732\n"
     ]
    }
   ],
   "source": [
    "def split_data(data, rng, train_ratio=0.85):\n",
    "    data_shuffled = data.copy()\n",
    "    rng.shuffle(data_shuffled)\n",
    "    train_size = int(len(data_shuffled) * train_ratio)\n",
    "    train = data_shuffled[:train_size]\n",
    "    test = data_shuffled[train_size:]\n",
    "    return train, test\n",
    "\n",
    "phase1_train, phase1_test = split_data(phase1_data, seed1)\n",
    "phase2_train, phase2_test = split_data(phase2_data, seed1)\n",
    "phase3_train, phase3_test = split_data(phase3_data, seed1)\n",
    "\n",
    "print(f\"Phase 1 - Train: {len(phase1_train)}, Test: {len(phase1_test)}\")\n",
    "print(f\"Phase 2 - Train: {len(phase2_train)}, Test: {len(phase2_test)}\")\n",
    "print(f\"Phase 3 - Train: {len(phase3_train)}, Test: {len(phase3_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aab726",
   "metadata": {},
   "source": [
    "## Sample Past Phase Data for Replay\n",
    "\n",
    "To simulate temporal memory and curriculum learning, sample 25% of data from earlier phases to include in the next phase:\n",
    "\n",
    "- Phase 2 receives a 25% sample of Phase 1 data using seed 42.\n",
    "- Phase 3 receives 25% from **both** Phase 1 and Phase 2:\n",
    "  - A new seed (43) is used for sampling Phase 1 (to avoid overlap with earlier Phase 2 inclusion).\n",
    "  - Seed 42 is reused for Phase 2 sampling.\n",
    "\n",
    "Train/test splits are again maintained within these sampled subsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b77a336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_for_merge(prev_train, prev_test, percent, rng):\n",
    "    n_prev = len(prev_train) + len(prev_test)\n",
    "    n_sample = int(n_prev * percent)\n",
    "    combined = prev_train + prev_test\n",
    "    rng.shuffle(combined)\n",
    "    merge_sample = combined[:n_sample]\n",
    "    n_train = int(len(merge_sample) * 0.85)\n",
    "    merge_train = merge_sample[:n_train]\n",
    "    merge_test = merge_sample[n_train:]\n",
    "    return merge_train, merge_test\n",
    "\n",
    "# For phase 2: add 25% of phase 1 to phase 2 splits (separately for train/test)\n",
    "phase1_merge_train2, phase1_merge_test2 = sample_for_merge(phase1_train, phase1_test, 0.25, seed1)\n",
    "\n",
    "seed2 = random.Random(43)\n",
    "\n",
    "# For phase 3: add 25% of phase 1 and phase 2 to phase 3 splits with different seed making data sampling from phase 1 is different\n",
    "phase1_merge_train3, phase1_merge_test3 = sample_for_merge(phase1_train, phase1_test, 0.25, seed2)\n",
    "phase2_merge_train3, phase2_merge_test3 = sample_for_merge(phase2_train, phase2_test, 0.25, seed1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f713462",
   "metadata": {},
   "source": [
    "## Merge Replay Data and Deduplicate\n",
    "\n",
    "Merge the sampled data into each phase and ensure uniqueness:\n",
    "\n",
    "- For Phase 2: merge in the sampled subset of Phase 1.\n",
    "- For Phase 3: merge in the sampled subsets from both Phase 1 and Phase 2.\n",
    "\n",
    "Conversations are deduplicated by converting to JSON strings, ensuring no duplicated threads across phases or replay iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dacdd6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2 - Final Train: 5291, Final Test: 935\n",
      "Phase 3 - Final Train: 5878, Final Test: 1039\n"
     ]
    }
   ],
   "source": [
    "def merge_and_deduplicate(primary_train, primary_test, merges_train, merges_test):\n",
    "    train_merged = primary_train + sum(merges_train, [])\n",
    "    test_merged = primary_test + sum(merges_test, [])\n",
    "\n",
    "    # Deduplicate: serialize as JSON strings, collect into set, then parse back\n",
    "    def dedup(convs):\n",
    "        seen = set()\n",
    "        unique = []\n",
    "        for conv in convs:\n",
    "            as_str = json.dumps(conv, sort_keys=True)\n",
    "            if as_str not in seen:\n",
    "                seen.add(as_str)\n",
    "                unique.append(conv)\n",
    "        return unique\n",
    "\n",
    "    train_merged_unique = dedup(train_merged)\n",
    "    test_merged_unique = dedup(test_merged)\n",
    "    return train_merged_unique, test_merged_unique\n",
    "\n",
    "# Phase 2: add phase 1 merge\n",
    "phase2_train_final, phase2_test_final = merge_and_deduplicate(\n",
    "    phase2_train, phase2_test,\n",
    "    [phase1_merge_train2], [phase1_merge_test2]\n",
    ")\n",
    "\n",
    "# Phase 3: add phase 1 and 2 merges\n",
    "phase3_train_final, phase3_test_final = merge_and_deduplicate(\n",
    "    phase3_train, phase3_test,\n",
    "    [phase1_merge_train3, phase2_merge_train3], [phase1_merge_test3, phase2_merge_test3]\n",
    ")\n",
    "\n",
    "print(f\"Phase 2 - Final Train: {len(phase2_train_final)}, Final Test: {len(phase2_test_final)}\")\n",
    "print(f\"Phase 3 - Final Train: {len(phase3_train_final)}, Final Test: {len(phase3_test_final)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e30ee",
   "metadata": {},
   "source": [
    "## Save Final Train/Test Splits\n",
    "\n",
    "Export the final train and test datasets for all three phases to disk as JSON files.  \n",
    "These files (`phase*_train.json` and `phase*_test.json`) will be used as input to the training scripts and evaluations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09a292de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "save_json(phase1_train, 'phase1_train.json')\n",
    "save_json(phase1_test, 'phase1_test.json')\n",
    "\n",
    "save_json(phase2_train_final, 'phase2_train.json')\n",
    "save_json(phase2_test_final, 'phase2_test.json')\n",
    "\n",
    "save_json(phase3_train_final, 'phase3_train.json')\n",
    "save_json(phase3_test_final, 'phase3_test.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
